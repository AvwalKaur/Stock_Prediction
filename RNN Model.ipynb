{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9139610,"sourceType":"datasetVersion","datasetId":5519750}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-29T14:25:24.135274Z","iopub.execute_input":"2024-08-29T14:25:24.135690Z","iopub.status.idle":"2024-08-29T14:25:25.410859Z","shell.execute_reply.started":"2024-08-29T14:25:24.135656Z","shell.execute_reply":"2024-08-29T14:25:25.408966Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/nvdia-stock-price/NVDIA.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:25.413060Z","iopub.execute_input":"2024-08-29T14:25:25.413609Z","iopub.status.idle":"2024-08-29T14:25:26.539818Z","shell.execute_reply.started":"2024-08-29T14:25:25.413563Z","shell.execute_reply":"2024-08-29T14:25:26.535370Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/nvdia-stock-price/NVDIA.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/nvdia-stock-price/NVDIA.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/nvdia-stock-price/NVDIA.csv'","output_type":"error"}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.541036Z","iopub.status.idle":"2024-08-29T14:25:26.541525Z","shell.execute_reply.started":"2024-08-29T14:25:26.541304Z","shell.execute_reply":"2024-08-29T14:25:26.541324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting into training and validation set\nlength_data=len(data)                      #rows that data has\nsplit_ratio=0.7   #                         %70 train + %30 validation\nlength_train=round(length_data*split_ratio)\nlength_validation=length_data-length_train\nprint(\"Data length :\", length_data)\nprint(\"Train data length :\", length_train)\nprint(\"Validation data lenth :\", length_validation)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.542894Z","iopub.status.idle":"2024-08-29T14:25:26.543361Z","shell.execute_reply.started":"2024-08-29T14:25:26.543130Z","shell.execute_reply":"2024-08-29T14:25:26.543154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=data[:length_train].iloc[:,:2]\ntrain_data['Date']=pd.to_datetime(train_data['Date']) #converting date time object\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.544743Z","iopub.status.idle":"2024-08-29T14:25:26.545162Z","shell.execute_reply.started":"2024-08-29T14:25:26.544944Z","shell.execute_reply":"2024-08-29T14:25:26.544961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data = data[length_train:].iloc[:,:2]\nvalidation_data['Date'] = pd.to_datetime(validation_data['Date'])  # converting to date time object\nvalidation_data","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.546485Z","iopub.status.idle":"2024-08-29T14:25:26.546929Z","shell.execute_reply.started":"2024-08-29T14:25:26.546697Z","shell.execute_reply":"2024-08-29T14:25:26.546715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating train data set from train split\n#reshaping the open data for easy access by the model into many rows and 1 column model\ndataset_train = train_data.Open.values\ndataset_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.549188Z","iopub.status.idle":"2024-08-29T14:25:26.549597Z","shell.execute_reply.started":"2024-08-29T14:25:26.549397Z","shell.execute_reply":"2024-08-29T14:25:26.549414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change 1d array to 2d array\n# Changing shape from (1692,) to (1692,1)\ndataset_train = np.reshape(dataset_train, (-1,1))\ndataset_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.552282Z","iopub.status.idle":"2024-08-29T14:25:26.552719Z","shell.execute_reply.started":"2024-08-29T14:25:26.552510Z","shell.execute_reply":"2024-08-29T14:25:26.552528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature scaling / data set convertion to 0 and 1 \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0,1))\n\n\n# scaling dataset\ndataset_train_scaled = scaler.fit_transform(dataset_train)\n\ndataset_train_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.553989Z","iopub.status.idle":"2024-08-29T14:25:26.554429Z","shell.execute_reply.started":"2024-08-29T14:25:26.554218Z","shell.execute_reply":"2024-08-29T14:25:26.554235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize = (15,6))\nplt.plot(dataset_train_scaled)\nplt.xlabel(\"Days as 1st, 2nd, 3rd..\")\nplt.ylabel(\"Open Price\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.557001Z","iopub.status.idle":"2024-08-29T14:25:26.558185Z","shell.execute_reply.started":"2024-08-29T14:25:26.557937Z","shell.execute_reply":"2024-08-29T14:25:26.557958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We have train data composed of stock open prices over days\n* So, it has 1184 prices corresponding 1184 days\n* My aim is to predict the open price of the next day.\n* I can use a time step of 50 days.\n* I will pick first 50 open prices (0 to 50), 1st 50 price will be in X_train data\n* Then predict the price of 51th day; and 51th price will be in y_train data\n* Again, i will pick prices from 1 to 51, those will be in X_train data\n* Then predict the next days price, 52nd price will be in y_train data","metadata":{}},{"cell_type":"code","source":"X_train=[]\ny_train=[]\n\ntime_step=50\n\nfor i in range (time_step,length_train):\n    X_train.append(dataset_train_scaled[i-time_step:i,0])\n    y_train.append(dataset_train_scaled[i,0])\n    \n# convert list to array\nX_train, y_train = np.array(X_train), np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.559505Z","iopub.status.idle":"2024-08-29T14:25:26.559903Z","shell.execute_reply.started":"2024-08-29T14:25:26.559713Z","shell.execute_reply":"2024-08-29T14:25:26.559730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X_train before reshape :\",X_train.shape)\nprint(\"Shape of y_train before reshape :\",y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.561412Z","iopub.status.idle":"2024-08-29T14:25:26.561823Z","shell.execute_reply.started":"2024-08-29T14:25:26.561628Z","shell.execute_reply":"2024-08-29T14:25:26.561646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**reshape**","metadata":{}},{"cell_type":"code","source":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\ny_train = np.reshape(y_train, (y_train.shape[0],1))\n\nprint(\"Shape of X_train after reshape :\",X_train.shape)\nprint(\"Shape of y_train after reshape :\",y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.563971Z","iopub.status.idle":"2024-08-29T14:25:26.564414Z","shell.execute_reply.started":"2024-08-29T14:25:26.564205Z","shell.execute_reply":"2024-08-29T14:25:26.564223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Shape of X_train : 1134 x 50 x 1\n* That means we have 1134 rows, each row has 50 rows and 1 column\n* Lets check the first row: it has 50 rows (open prices of 49 days)","metadata":{}},{"cell_type":"code","source":"X_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.566286Z","iopub.status.idle":"2024-08-29T14:25:26.566703Z","shell.execute_reply.started":"2024-08-29T14:25:26.566503Z","shell.execute_reply":"2024-08-29T14:25:26.566521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#price of the 50th day\ny_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.568865Z","iopub.status.idle":"2024-08-29T14:25:26.569313Z","shell.execute_reply.started":"2024-08-29T14:25:26.569080Z","shell.execute_reply":"2024-08-29T14:25:26.569121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating RNN model","metadata":{}},{"cell_type":"code","source":"# importing libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# initializing the RNN\nregressor = Sequential()\n\n# adding first RNN layer and dropout regulatization\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True, \n              input_shape = (X_train.shape[1],1))\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n\n# adding second RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding third RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding fourth RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding the output layer\nregressor.add(Dense(units = 1))\n\n# compiling RNN\nregressor.compile(\n    optimizer = \"adam\", \n    loss = \"mean_squared_error\",\n    metrics = [\"accuracy\"])\n\n# fitting the RNN\nhistory = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.570543Z","iopub.status.idle":"2024-08-29T14:25:26.570952Z","shell.execute_reply.started":"2024-08-29T14:25:26.570748Z","shell.execute_reply":"2024-08-29T14:25:26.570766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluating the model\nhistory.history[\"loss\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.572465Z","iopub.status.idle":"2024-08-29T14:25:26.572864Z","shell.execute_reply.started":"2024-08-29T14:25:26.572674Z","shell.execute_reply":"2024-08-29T14:25:26.572691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting loss vs epochs\n# Plotting Loss vs Epochs\nplt.figure(figsize =(10,7))\nplt.plot(history.history[\"loss\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.title(\"Simple RNN model, Loss vs Epoch\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.574309Z","iopub.status.idle":"2024-08-29T14:25:26.574730Z","shell.execute_reply.started":"2024-08-29T14:25:26.574534Z","shell.execute_reply":"2024-08-29T14:25:26.574551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Accuracy vs Epochs\nplt.figure(figsize =(10,5))\nplt.plot(history.history[\"accuracy\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Simple RNN model, Accuracy vs Epoch\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.576687Z","iopub.status.idle":"2024-08-29T14:25:26.577093Z","shell.execute_reply.started":"2024-08-29T14:25:26.576900Z","shell.execute_reply":"2024-08-29T14:25:26.576917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model prediction for train data\n","metadata":{}},{"cell_type":"code","source":"y_pred = regressor.predict(X_train)  # predictions\ny_pred = scaler.inverse_transform(y_pred) # scaling back from 0-1 to original\ny_pred.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.578414Z","iopub.status.idle":"2024-08-29T14:25:26.578798Z","shell.execute_reply.started":"2024-08-29T14:25:26.578613Z","shell.execute_reply":"2024-08-29T14:25:26.578629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = scaler.inverse_transform(y_train) # scaling back from 0-1 to original\ny_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.580002Z","iopub.status.idle":"2024-08-29T14:25:26.580425Z","shell.execute_reply.started":"2024-08-29T14:25:26.580225Z","shell.execute_reply":"2024-08-29T14:25:26.580241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualisation\nplt.figure(figsize = (30,10))\nplt.plot(y_pred, color = \"b\", label = \"y_pred\" )\nplt.plot(y_train, color = \"g\", label = \"y_train\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Predictions with input X_train vs y_train\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.581515Z","iopub.status.idle":"2024-08-29T14:25:26.581905Z","shell.execute_reply.started":"2024-08-29T14:25:26.581715Z","shell.execute_reply":"2024-08-29T14:25:26.581732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"creating test data from validation data\n","metadata":{}},{"cell_type":"markdown","source":"Converting array and scaling\n","metadata":{}},{"cell_type":"code","source":"dataset_validation = validation_data.Open.values  # getting \"open\" column and converting to array\ndataset_validation = np.reshape(dataset_validation, (-1,1))  # converting 1D to 2D array\nscaled_dataset_validation =  scaler.fit_transform(dataset_validation)  # scaling open values to between 0 and 1\nprint(\"Shape of scaled validation dataset :\",scaled_dataset_validation.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.583185Z","iopub.status.idle":"2024-08-29T14:25:26.583592Z","shell.execute_reply.started":"2024-08-29T14:25:26.583392Z","shell.execute_reply":"2024-08-29T14:25:26.583409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating X_test and y_test\nX_test = []\ny_test = []\n\nfor i in range(time_step, length_validation):\n    X_test.append(scaled_dataset_validation[i-time_step:i,0])\n    y_test.append(scaled_dataset_validation[i,0])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.584799Z","iopub.status.idle":"2024-08-29T14:25:26.585241Z","shell.execute_reply.started":"2024-08-29T14:25:26.585009Z","shell.execute_reply":"2024-08-29T14:25:26.585025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting to array\nX_test, y_test = np.array(X_test), np.array(y_test)\nprint(\"Shape of X_test before reshape :\",X_test.shape)\nprint(\"Shape of y_test before reshape :\",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.586598Z","iopub.status.idle":"2024-08-29T14:25:26.587001Z","shell.execute_reply.started":"2024-08-29T14:25:26.586813Z","shell.execute_reply":"2024-08-29T14:25:26.586829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))  # reshape to 3D array\ny_test = np.reshape(y_test, (-1,1))  # reshape to 2D array","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.588445Z","iopub.status.idle":"2024-08-29T14:25:26.588848Z","shell.execute_reply.started":"2024-08-29T14:25:26.588656Z","shell.execute_reply":"2024-08-29T14:25:26.588672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X_test after reshape :\",X_test.shape)\nprint(\"Shape of y_test after reshape :\",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.589899Z","iopub.status.idle":"2024-08-29T14:25:26.590316Z","shell.execute_reply.started":"2024-08-29T14:25:26.590118Z","shell.execute_reply":"2024-08-29T14:25:26.590140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions with X_test data\ny_pred_of_test = regressor.predict(X_test)\n# scaling back from 0-1 to original\ny_pred_of_test = scaler.inverse_transform(y_pred_of_test) \nprint(\"Shape of y_pred_of_test :\",y_pred_of_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.593004Z","iopub.status.idle":"2024-08-29T14:25:26.593429Z","shell.execute_reply.started":"2024-08-29T14:25:26.593230Z","shell.execute_reply":"2024-08-29T14:25:26.593248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualisation\nplt.figure(figsize = (30,10))\nplt.plot(y_pred_of_test, label = \"y_pred_of_test\", c = \"orange\")\nplt.plot(scaler.inverse_transform(y_test), label = \"y_test\", c = \"g\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Prediction with input X_test vs y_test\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.594884Z","iopub.status.idle":"2024-08-29T14:25:26.595318Z","shell.execute_reply.started":"2024-08-29T14:25:26.595088Z","shell.execute_reply":"2024-08-29T14:25:26.595130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualisation\nplt.subplots(figsize =(30,12))\nplt.plot(train_data.Date, train_data.Open, label = \"train_data\", color = \"b\")\nplt.plot(validation_data.Date, validation_data.Open, label = \"validation_data\", color = \"g\")\nplt.plot(train_data.Date.iloc[time_step:], y_pred, label = \"y_pred\", color = \"r\")\nplt.plot(validation_data.Date.iloc[time_step:], y_pred_of_test, label = \"y_pred_of_test\", color = \"orange\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Train-Validation-Prediction\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.597384Z","iopub.status.idle":"2024-08-29T14:25:26.597774Z","shell.execute_reply.started":"2024-08-29T14:25:26.597585Z","shell.execute_reply":"2024-08-29T14:25:26.597602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.iloc[-1]","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.598936Z","iopub.status.idle":"2024-08-29T14:25:26.599335Z","shell.execute_reply.started":"2024-08-29T14:25:26.599146Z","shell.execute_reply":"2024-08-29T14:25:26.599163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We can predict the open price for the day after 8/8/2024-> for 9/8/2024.\n* We will use last 50 days Open price as input of our model for this prediction\n* Let us prepare it:","metadata":{}},{"cell_type":"code","source":"X_input = data.iloc[-time_step:].Open.values               # getting last 50 rows and converting to array\nX_input = scaler.fit_transform(X_input.reshape(-1,1))      # converting to 2D array and scaling\nX_input = np.reshape(X_input, (1,50,1))                    # reshaping : converting to 3D array\nprint(\"Shape of X_input :\", X_input.shape)\nX_input","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.600708Z","iopub.status.idle":"2024-08-29T14:25:26.601089Z","shell.execute_reply.started":"2024-08-29T14:25:26.600900Z","shell.execute_reply":"2024-08-29T14:25:26.600916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_RNN_prediction = scaler.inverse_transform(regressor.predict(X_input))\n\nprint(\"Simple RNN, Open price prediction for 9/8/2024      :\", simple_RNN_prediction[0,0])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:25:26.602577Z","iopub.status.idle":"2024-08-29T14:25:26.602957Z","shell.execute_reply.started":"2024-08-29T14:25:26.602773Z","shell.execute_reply":"2024-08-29T14:25:26.602789Z"},"trusted":true},"execution_count":null,"outputs":[]}]}